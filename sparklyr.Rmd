---
title: "Untitled"
output: html_document
date: "2022-06-08"
---

Open a new terminal in the RStudio Server to load `~/keys/gcloud-auth.sh`.
Type `kubectl cluster-info` to get the 'master' for the 'spark_config_kubernetes'.

```{r}
library(sparklyr)
conf <- spark_config_kubernetes(
  master = "k8s://https://34.136.32.95", # Type kubectl cluster-info to get this url.
  version = "3.3",
  image = "us-central1-docker.pkg.dev/project-lee-1/docker/spark:3.3.0",
  driver = "sparklyr",
  account = "admin", # Use the system account created by install-gcloud.sh
  jars = "local:///opt/sparklyr",
  executors = 10
)
conf$sparklyr.shell.conf <- c( # The following settings should be here to be used for spark-submit.
  conf$sparklyr.shell.conf,
  "spark.kubernetes.namespace=cluster", # Use the namespace created by install-gcloud.sh
  "spark.driver.cores=4",
  "spark.driver.memory=16g"
)
conf$spark.executor.cores <- 1
conf$spark.executor.memory <- "4g"
```

```{r}
sc <- spark_connect(
  config = conf,
  spark_home = "/opt/spark/3.3.0" # Use the folder where Spark was installed by spark.sh
)
```

```{r}
connection_is_open(sc)
```

Go to a terminal on the virtual machine and press "shift + ` +  c" to request local forward for 4040.
Type `kubectl port-forward pod/sparklyr 4040:4040` on the virtual machine.
Then go to `localhost:4040` in the web browser on the local machine to access Spark Web UI.

```{r}
tbl_mtcars <- copy_to(sc, mtcars, "spark_mtcars")
```

```{r}
partitions <- tbl_mtcars %>%
  select(mpg, wt, cyl) %>%
  sdf_random_split(training = 0.5, test = 0.5, seed = 1099)
```

```{r}
fit <- partitions$training %>%
  ml_linear_regression(mpg ~ .)

fit
```

```{r}
summary(fit)
```

```{r}
spark_disconnect(sc)
```

```{r}
system2("pkill", "kubectl") # Cancel port forward.
system2("kubectl", "delete pods --all") # Delete all pods.
```

Using the terminal in RStudio Server, type `gcloud container clusters resize cluster-1 --num-nodes=0 --zone=us-central1-c --async` to resize the cluster to 0 node.

